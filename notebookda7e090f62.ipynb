{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\n\nprint(\" Cleaning up old files to prevent errors...\")\nshutil.rmtree(\"/kaggle/working/dataset\", ignore_errors=True)\n\n\n!pip install -q gdown\n\n\nfiles_to_download = {\n    \"Train_Part1.zip\": \"1QtSOBpyXyqiGRNEFsYZUe2Ln2j3zwp2E\",\n    \"Train_Part2.zip\": \"1_HDaXfDzxpgF8ESDpG1dU4aOoLt8x08k\",\n    \"Train_Part3.zip\": \"1Pcd6nNwAaVttyCDGK60BnoAFhhwtypq_\",\n    \"Validation.zip\":  \"1lI3Y3UsDlsrYUMQWvd9O7L6QwgcY4pjx\"\n}\n# ==========================================\n\n\noutput_dir = \"/kaggle/working/dataset\"\nos.makedirs(output_dir, exist_ok=True)\n\nprint(f\" Starting fresh download of {len(files_to_download)} files...\")\n\nfor filename, file_id in files_to_download.items():\n    print(f\"   Downloading {filename}...\")\n    !gdown --id {file_id} -O {filename}\n    \n    print(f\"   Unzipping {filename}...\")\n    !unzip -qo {filename} -d {output_dir}\n    \n    os.remove(filename)\n\nprint(\" All files downloaded and merged successfully!\")\nprint(f\"ðŸ“‚ Data is located at: {output_dir}\") \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T11:22:20.412034Z","iopub.execute_input":"2025-12-30T11:22:20.412621Z","iopub.status.idle":"2025-12-30T11:24:14.241179Z","shell.execute_reply.started":"2025-12-30T11:22:20.412594Z","shell.execute_reply":"2025-12-30T11:24:14.240434Z"}},"outputs":[{"name":"stdout","text":" Cleaning up old files to prevent errors...\n Starting fresh download of 4 files...\n   Downloading Train_Part1.zip...\n/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1QtSOBpyXyqiGRNEFsYZUe2Ln2j3zwp2E\nFrom (redirected): https://drive.google.com/uc?id=1QtSOBpyXyqiGRNEFsYZUe2Ln2j3zwp2E&confirm=t&uuid=28e2de00-31c0-4cd4-8740-da5fccfb9675\nTo: /kaggle/working/Train_Part1.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.15G/2.15G [00:23<00:00, 90.9MB/s]\n   Unzipping Train_Part1.zip...\n   Downloading Train_Part2.zip...\n/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1_HDaXfDzxpgF8ESDpG1dU4aOoLt8x08k\nFrom (redirected): https://drive.google.com/uc?id=1_HDaXfDzxpgF8ESDpG1dU4aOoLt8x08k&confirm=t&uuid=522390ef-05de-4164-b124-48faf6afe8c7\nTo: /kaggle/working/Train_Part2.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.15G/2.15G [00:17<00:00, 121MB/s]\n   Unzipping Train_Part2.zip...\n   Downloading Train_Part3.zip...\n/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1Pcd6nNwAaVttyCDGK60BnoAFhhwtypq_\nFrom (redirected): https://drive.google.com/uc?id=1Pcd6nNwAaVttyCDGK60BnoAFhhwtypq_&confirm=t&uuid=0d67e26b-9b17-472d-8d0c-24ca8d9f35b4\nTo: /kaggle/working/Train_Part3.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 534M/534M [00:06<00:00, 79.4MB/s]\n   Unzipping Train_Part3.zip...\n   Downloading Validation.zip...\n/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1lI3Y3UsDlsrYUMQWvd9O7L6QwgcY4pjx\nFrom (redirected): https://drive.google.com/uc?id=1lI3Y3UsDlsrYUMQWvd9O7L6QwgcY4pjx&confirm=t&uuid=fc70df8c-f974-4579-b91b-b17ab4892384\nTo: /kaggle/working/Validation.zip\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.38G/1.38G [00:12<00:00, 114MB/s]\n   Unzipping Validation.zip...\n All files downloaded and merged successfully!\nðŸ“‚ Data is located at: /kaggle/working/dataset\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q \"monai[nibabel, tqdm]\" torch torchvision\nprint(\" Libraries installed!\")\n\nimport os\nimport glob\nimport torch\nimport numpy as np\nfrom monai.transforms import (\n    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,\n    NormalizeIntensityd, RandCropByPosNegLabeld, RandFlipd, MapTransform\n)\nfrom monai.networks.nets import SegResNet\nfrom monai.losses import DiceLoss\nfrom monai.data import CacheDataset, DataLoader\nfrom monai.inferers import sliding_window_inference\n\n\ndata_dir = '/kaggle/working/dataset/Healing_Algorithms_Training_Data'\nfiles = glob.glob(os.path.join(data_dir, \"HelioGLI*\"))\nprint(f\" Training Data Directory: {data_dir}\")\nprint(f\" Found {len(files)} patients. Ready to train!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T11:24:14.242994Z","iopub.execute_input":"2025-12-30T11:24:14.243281Z","iopub.status.idle":"2025-12-30T11:24:54.526676Z","shell.execute_reply.started":"2025-12-30T11:24:14.243254Z","shell.execute_reply":"2025-12-30T11:24:54.525994Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h Libraries installed!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n  if entities is not ():\n2025-12-30 11:24:40.173356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767093880.342352      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767093880.389361      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767093880.818504      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767093880.818541      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767093880.818544      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767093880.818547      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":" Training Data Directory: /kaggle/working/dataset/Healing_Algorithms_Training_Data\n Found 236 patients. Ready to train!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport glob\nimport torch\nfrom monai.transforms import (\n    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,\n    NormalizeIntensityd, RandCropByPosNegLabeld, RandFlipd, MapTransform\n)\nfrom monai.data import Dataset, DataLoader\n\ndata_dir = '/kaggle/working/dataset'\n\nclass ConvertToBratsClassesd(MapTransform):\n    def __call__(self, data):\n        d = dict(data)\n        for key in self.keys:\n            result = []\n            \n            result.append(torch.logical_or(d[key] == 2, d[key] == 4))\n            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 4), d[key] == 1))\n            result.append(d[key] == 2)\n            d[key] = torch.stack(result, axis=0).float()\n        return d\n\ntrain_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\"]),\n    ConvertToBratsClassesd(keys=[\"label\"]),\n    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n    RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=(128, 128, 128), pos=1, neg=1, num_samples=1),\n    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n])\n\nval_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\"]),\n    ConvertToBratsClassesd(keys=[\"label\"]),\n    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n])\n\nprint(f\" Searching for patient folders inside {data_dir}...\")\n\npatient_folders = sorted(glob.glob(os.path.join(data_dir, \"**\", \"HelioGLI-*\"), recursive=True))\n\nif not patient_folders:\n    patient_folders = sorted(glob.glob(os.path.join(data_dir, \"**\", \"Helio*\"), recursive=True))\n\nprint(f\" Found {len(patient_folders)} patient folders.\")\n\n\ndata_dicts = []\n\nfor subject_path in patient_folders:\n   \n    if not os.path.isdir(subject_path):\n        continue\n        \n    all_files = os.listdir(subject_path)\n\n    def get_file(key):\n        for f in all_files:\n            if key in f and f.endswith('.nii.gz'):\n                return os.path.join(subject_path, f)\n        return None\n\n    try:\n        t1n = get_file(\"t1n\")\n        t1c = get_file(\"t1c\")\n        t2w = get_file(\"t2w\")\n        t2f = get_file(\"t2f\")\n        seg = get_file(\"seg\")\n\n        if None in [t1n, t1c, t2w, t2f, seg]:\n            continue\n\n        data_dicts.append({\n            \"image\": [t1n, t1c, t2w, t2f],\n            \"label\": seg\n        })\n    except Exception:\n        continue\n\nif not data_dicts:\n    raise RuntimeError(\" No valid data found! Please check if your zip extracted correctly.\")\n\nsplit_idx = int(len(data_dicts) * 0.8)\ntrain_files, val_files = data_dicts[:split_idx], data_dicts[split_idx:]\n\nprint(f\" Data split: {len(train_files)} training, {len(val_files)} validation\")\n\ntrain_ds = Dataset(data=train_files, transform=train_transforms)\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\n\nval_ds = Dataset(data=val_files, transform=val_transforms)\nval_loader = DataLoader(val_ds, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T11:24:54.527648Z","iopub.execute_input":"2025-12-30T11:24:54.528293Z","iopub.status.idle":"2025-12-30T11:24:54.595055Z","shell.execute_reply.started":"2025-12-30T11:24:54.528255Z","shell.execute_reply":"2025-12-30T11:24:54.594408Z"}},"outputs":[{"name":"stdout","text":" Searching for patient folders inside /kaggle/working/dataset...\n Found 604 patient folders.\n Data split: 483 training, 121 validation\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n  warn_deprecated(argname, msg, warning_category)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom monai.networks.nets import SegResNet\nfrom monai.losses import DiceLoss\nfrom monai.inferers import sliding_window_inference\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SegResNet(\n    spatial_dims=3, in_channels=4, out_channels=3, \n    init_filters=16, dropout_prob=0.2\n).to(device)\n\nloss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\noptimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\nscaler = torch.amp.GradScaler('cuda')\n\nmax_epochs = 5\nval_interval = 1\nbest_metric = -1\nbest_metric_epoch = -1\n\nprint(f\" Phase 1: Warming up for {max_epochs} epochs...\")\n\nfor epoch in range(max_epochs):\n    model.train()\n    epoch_loss = 0\n    step = 0\n    \n    for batch_data in train_loader:\n        step += 1\n        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n        optimizer.zero_grad()\n        \n        with torch.amp.autocast('cuda'):\n            outputs = model(inputs)\n            loss = loss_function(outputs, labels)\n            \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        epoch_loss += loss.item()\n\n    print(f\"Epoch {epoch + 1}/{max_epochs}, Train Loss: {epoch_loss/step:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            dice_vals = []\n            for val_data in val_loader:\n                val_inputs, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n                val_outputs = sliding_window_inference(val_inputs, (128, 128, 128), 4, model, overlap=0.5)\n                val_outputs = (val_outputs.sigmoid() > 0.5).float()\n                dice = (2 * (val_outputs * val_labels).sum()) / (val_outputs.sum() + val_labels.sum() + 1e-5)\n                dice_vals.append(dice.item())\n            \n            mean_dice = np.mean(dice_vals)\n            print(f\"Validation Dice: {mean_dice:.4f}\")\n            \n        \n            if mean_dice > best_metric:\n                best_metric = mean_dice\n                best_metric_epoch = epoch + 1\n                torch.save(model.state_dict(), \"best_metric_model.pth\")\n                print(\" Model Saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T11:24:54.595872Z","iopub.execute_input":"2025-12-30T11:24:54.596075Z","iopub.status.idle":"2025-12-30T12:46:52.664929Z","shell.execute_reply.started":"2025-12-30T11:24:54.596052Z","shell.execute_reply":"2025-12-30T12:46:52.664206Z"}},"outputs":[{"name":"stdout","text":" Phase 1: Warming up for 5 epochs...\nEpoch 1/5, Train Loss: 0.8261\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/monai/inferers/utils.py:226: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n  win_data = torch.cat([inputs[win_slice] for win_slice in unravel_slice]).to(sw_device)\n/usr/local/lib/python3.12/dist-packages/monai/inferers/utils.py:370: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n  out[idx_zm] += p\n","output_type":"stream"},{"name":"stdout","text":"Validation Dice: 0.1583\n Model Saved!\nEpoch 2/5, Train Loss: 0.7371\nValidation Dice: 0.5002\n Model Saved!\nEpoch 3/5, Train Loss: 0.6357\nValidation Dice: 0.7096\n Model Saved!\nEpoch 4/5, Train Loss: 0.5107\nValidation Dice: 0.7413\n Model Saved!\nEpoch 5/5, Train Loss: 0.4016\nValidation Dice: 0.7464\n Model Saved!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nfrom monai.inferers import sliding_window_inference\nfrom monai.transforms import (\n    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,\n    NormalizeIntensityd, RandCropByPosNegLabeld, RandFlipd\n)\nfrom monai.data import Dataset, DataLoader\n\nmax_epochs = 10\nval_interval = 1\nspatial_size = (128, 128, 128)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_transforms = Compose([\n    LoadImaged(keys=[\"image\", \"label\"]),\n    EnsureChannelFirstd(keys=[\"image\"]),\n    ConvertToBratsClassesd(keys=[\"label\"]),\n    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n    RandCropByPosNegLabeld(keys=[\"image\", \"label\"], label_key=\"label\", spatial_size=spatial_size, pos=1, neg=1, num_samples=1),\n    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n])\n\ntrain_ds = Dataset(data=train_files, transform=train_transforms)\ntrain_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\n\nif os.path.exists(\"best_metric_model.pth\"):\n    model.load_state_dict(torch.load(\"best_metric_model.pth\"))\n\noptimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\nscaler = torch.amp.GradScaler('cuda')\n\nbest_metric = 0.7786\n\nfor epoch in range(max_epochs):\n    model.train()\n    epoch_loss = 0\n    step = 0\n\n    for batch_data in train_loader:\n        step += 1\n        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n        optimizer.zero_grad()\n\n        with torch.amp.autocast('cuda'):\n            outputs = model(inputs)\n            loss = loss_function(outputs, labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        epoch_loss += loss.item()\n\n    scheduler.step()\n    print(f\"Epoch {epoch + 1}/{max_epochs}, Train Loss: {epoch_loss/step:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            dice_vals = []\n            for val_data in val_loader:\n                val_inputs, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n                \n                val_outputs = sliding_window_inference(val_inputs, (128, 128, 128), 4, model, overlap=0.5)\n                val_outputs = (val_outputs.sigmoid() > 0.5).float()\n                \n                dice = (2 * (val_outputs * val_labels).sum()) / (val_outputs.sum() + val_labels.sum() + 1e-5)\n                dice_vals.append(dice.item())\n\n            mean_dice = np.mean(dice_vals)\n            print(f\"Validation Dice: {mean_dice:.4f}\")\n\n            if mean_dice > best_metric:\n                best_metric = mean_dice\n                torch.save(model.state_dict(), \"best_metric_model.pth\")\n                print(\"New Best Model Saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:46:52.666911Z","iopub.execute_input":"2025-12-30T12:46:52.667208Z","iopub.status.idle":"2025-12-30T15:33:40.443366Z","shell.execute_reply.started":"2025-12-30T12:46:52.667175Z","shell.execute_reply":"2025-12-30T15:33:40.442488Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Train Loss: 0.3423\nValidation Dice: 0.6943\nEpoch 2/10, Train Loss: 0.3036\nValidation Dice: 0.7904\nNew Best Model Saved!\nEpoch 3/10, Train Loss: 0.2789\nValidation Dice: 0.7895\nEpoch 4/10, Train Loss: 0.2667\nValidation Dice: 0.8014\nNew Best Model Saved!\nEpoch 5/10, Train Loss: 0.2482\nValidation Dice: 0.8138\nNew Best Model Saved!\nEpoch 6/10, Train Loss: 0.2351\nValidation Dice: 0.7870\nEpoch 7/10, Train Loss: 0.2225\nValidation Dice: 0.8244\nNew Best Model Saved!\nEpoch 8/10, Train Loss: 0.2284\nValidation Dice: 0.8341\nNew Best Model Saved!\nEpoch 9/10, Train Loss: 0.2445\nValidation Dice: 0.8387\nNew Best Model Saved!\nEpoch 10/10, Train Loss: 0.2257\nValidation Dice: 0.8410\nNew Best Model Saved!\n","output_type":"stream"}],"execution_count":5}]}